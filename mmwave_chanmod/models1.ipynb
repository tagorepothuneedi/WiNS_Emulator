{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "models.py:  Classes for the modeling<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tfk = tf.keras\n",
    "tfkm = tf.keras.models\n",
    "tfkl = tf.keras.layers\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spherical import spherical_add_sub, cart_to_sph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhyConst(object):\n",
    "    \"\"\"\n",
    "    Physical constants\n",
    "    \"\"\"\n",
    "    light_speed = 2.99792458e8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFormat(object):\n",
    "    \"\"\"\n",
    "    Constants for data format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Indices for the angle data\n",
    "    aoa_phi_ind = 0\n",
    "    aoa_theta_ind = 1\n",
    "    aod_phi_ind = 2\n",
    "    aod_theta_ind = 3\n",
    "    nangle = 4\n",
    "    ang_name = ['AoA_Phi', 'AoA_theta', 'AoD_phi', 'AoD_theta']\n",
    "    \n",
    "    # Maximum number of paths\n",
    "    npaths_max = 25\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondVAE(object):\n",
    "    def __init__(self, nlatent, ndat, ncond, nunits_enc=(25,10,),\\\n",
    "                 nunits_dec=(10,25,), out_var_min=1e-4,\\\n",
    "                 init_kernel_stddev=10.0, init_bias_stddev=10.0,\\\n",
    "                 nsort=0):\n",
    "        \"\"\"\n",
    "        Conditional VAE class\n",
    "        Parameters\n",
    "        ----------\n",
    "        nlatent : int\n",
    "            number of latent states\n",
    "        ndat : int\n",
    "            number of features in the data to be modeled\n",
    "        ncond : int\n",
    "            number of conditional variables\n",
    "        nunits_enc : list of integers\n",
    "            number of hidden units in each layer of the encoder\n",
    "        nunits_dec : list of integers\n",
    "            number of hidden units in each layer of the decoder\n",
    "        nsort : int\n",
    "            Sort sthe first nsort values of the output.\n",
    "            This is used for the path loss data where nsort=npaths_max\n",
    "        out_var_min:  scalar\n",
    "            minimum output variance.  This is used for improved conditioning\n",
    "        init_kernel_stddev : scalar\n",
    "            std deviation of the kernel in the initialization\n",
    "        init_bias_stddev : scalar\n",
    "            std deviation of the bias in the initialization\n",
    "        \"\"\"   \n",
    "        self.nlatent = nlatent\n",
    "        self.ndat = ndat        \n",
    "        self.ncond = ncond\n",
    "        self.nunits_enc = nunits_enc\n",
    "        self.out_var_min = out_var_min\n",
    "        self.nsort = nsort\n",
    "        self.init_kernel_stddev = init_kernel_stddev\n",
    "        self.init_bias_stddev = init_bias_stddev\n",
    "        \n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        self.build_vae()\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        \"\"\"\n",
    "        Builds the encoder network\n",
    "        \n",
    "        The encoder maps [x,cond] to [z_mu, z_log_var]\n",
    "        \"\"\"\n",
    "        x = tfkl.Input((self.ndat,), name='x')\n",
    "        cond = tfkl.Input((self.ncond,), name='cond')\n",
    "        \n",
    "        dat_cond = tfkl.Concatenate(name='dat_cond')([x, cond])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Add the hidden layers\n",
    "        h = dat_cond\n",
    "        layer_names = []\n",
    "        for i in range(len(self.nunits_enc)):           \n",
    "            h = tfkl.Dense(self.nunits_enc[i], activation='sigmoid',\\\n",
    "                           name='FC%d' % i)(h)\n",
    "            layer_names.append('FC%d' % i)\n",
    "            \n",
    "        # Add the final output layer                \n",
    "        z_mu = tfkl.Dense(self.nlatent, activation='linear',\\\n",
    "                          bias_initializer=None, name='z_mu')(h)\n",
    "        z_log_var = tfkl.Dense(self.nlatent, activation='linear',\\\n",
    "                          bias_initializer=None, name='z_log_var')(h)\n",
    "                \n",
    "        # Save the encoder model\n",
    "        self.encoder = tfkm.Model([x, cond],\\\n",
    "                                  [z_mu, z_log_var])\n",
    "\n",
    "        # Set the initialization\n",
    "        set_initialization(self.encoder, layer_names,\\\n",
    "                           self.init_kernel_stddev, self.init_bias_stddev)        \n",
    "            \n",
    "    def reparm(self, z_mu, z_log_var):\n",
    "        \"\"\"\n",
    "        Re-parametrization layer\n",
    "        \n",
    "            z = z_mu + eps * tf.exp(z_log_var*0.5)\n",
    "            \n",
    "        where eps is unit Gaussian\n",
    "        \"\"\"\n",
    "        batch_shape = tf.shape(z_mu)\n",
    "        eps = tf.random.normal(shape=batch_shape)\n",
    "        z = eps * tf.exp(z_log_var*0.5) + z_mu\n",
    "        return z\n",
    "        \n",
    "        \n",
    "    def build_decoder(self):\n",
    "        \"\"\"\n",
    "        Builds the decoder network.\n",
    "        The decoder network is the generative model mapping:\n",
    "            \n",
    "            [z,cond] to xhat\n",
    "        \"\"\"   \n",
    "        # Input layer\n",
    "        z_samp = tfkl.Input((self.nlatent,), name='z')\n",
    "        cond = tfkl.Input((self.ncond,), name='cond')   \n",
    "        z_cond = tfkl.Concatenate(name='z_cond')([z_samp, cond])\n",
    "        \n",
    "        # Hidden layers\n",
    "        layer_names = []\n",
    "        h = z_cond\n",
    "        for i in range(len(self.nunits_enc)):            \n",
    "            h = tfkl.Dense(self.nunits_enc[i], activation='sigmoid',\\\n",
    "                           bias_initializer=None, name='FC%d' % i)(h)\n",
    "            layer_names.append('FC%d' % i)\n",
    "            \n",
    "        # Add the output mean \n",
    "        x_mu = tfkl.Dense(self.ndat, name='x_mu',\\\n",
    "                          bias_initializer=None)(h)\n",
    "        # Add sorting of the first path loss values \n",
    "        if self.nsort > 0:\n",
    "            x_mu_pl = x_mu[:,:self.nsort]            \n",
    "            x_mu_pl = tf.sort(x_mu_pl, direction='DESCENDING', axis=-1)\n",
    "            x_mu_ang = x_mu[:,self.nsort:]\n",
    "            x_mu = tfkl.Concatenate()([x_mu_pl, x_mu_ang])\n",
    "                                \n",
    "        # Add the output variance.                            \n",
    "        x_log_var = tfkl.Dense(self.ndat, name='x_log_var')(h)   \n",
    "        x_log_var = tf.maximum(x_log_var, np.log(self.out_var_min) )            \n",
    "        \n",
    "        # Build the decoder\n",
    "        self.decoder = tfkm.Model([z_samp, cond], [x_mu, x_log_var])\n",
    "        \n",
    "        # Set the initialization\n",
    "        set_initialization(self.decoder, layer_names,\\\n",
    "                           self.init_kernel_stddev, self.init_bias_stddev)      \n",
    "        \n",
    "        # Build the decoder with sampling\n",
    "        x_samp = self.reparm(x_mu, x_log_var)\n",
    "        self.sampler = tfkm.Model([z_samp, cond], x_samp)\n",
    "        \n",
    "        \n",
    "    def build_vae(self):\n",
    "        \"\"\"\n",
    "        Builds the VAE to train.  \n",
    "        \n",
    "        The VAE takes an input sample x and outputs [xhat,x_log_var].\n",
    "        It also has the reconstruction and KL divergence loss\n",
    "        \n",
    "        \"\"\"\n",
    "        # Build the encoder and decoder\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()\n",
    "        \n",
    "        # Inputs for the VAE\n",
    "        x = tfkl.Input((self.ndat,), name='x')\n",
    "        cond = tfkl.Input((self.ncond,), name='cond')\n",
    "        \n",
    "        # Encoder\n",
    "        z_mu, z_log_var = self.encoder([x,cond])\n",
    "        z_samp = self.reparm(z_mu, z_log_var)\n",
    "        \n",
    "        # Decoder\n",
    "        xhat, x_log_var = self.decoder([z_samp, cond])\n",
    "        self.vae = tfkm.Model([x, cond], [xhat, x_log_var])\n",
    "            \n",
    "        # Add reconstruction loss   \n",
    "        recon_loss = K.square(xhat - x)*tf.exp(-x_log_var) + x_log_var + \\\n",
    "            np.log(2*np.pi)\n",
    "        recon_loss = 0.5*K.sum(recon_loss, axis=-1)\n",
    "        \n",
    "        # Add the KL divergence loss\n",
    "        kl_loss = 1 + z_log_var - K.square(z_mu) - K.exp(z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        vae_loss = K.mean(recon_loss + kl_loss)\n",
    "        self.vae.add_loss(vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChanMod(object):\n",
    "    \"\"\"\n",
    "    Object for modeling mmWave channel model data.\n",
    "    \n",
    "    There are two parts in the model:\n",
    "        * link_mod:  This predicts the link_state (i.e. LOS, NLOS or no link)\n",
    "          from the link conditions.  This is implemented a neural network\n",
    "        * path_mod:  This predicts the other channel parameters (right now,\n",
    "          this is the vector of path losses) from the condition and link_state.\n",
    "        \n",
    "    Each model has a pre-processor on the data and conditions that is also\n",
    "    trained.\n",
    "          \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Static variables\n",
    "    \"\"\"\n",
    "    # Link states\n",
    "    no_link = 0\n",
    "    los_link = 1\n",
    "    nlos_link = 2\n",
    "    nlink_states = 3\n",
    "    \n",
    "    # Cell types\n",
    "    terr_cell = 0\n",
    "    aerial_cell = 1\n",
    "    ncell_type = 2\n",
    "    \n",
    "    # Numbers of transformed features for models\n",
    "    nin_link = 5   # num features for link predictor model\n",
    "    ncond = 5      # num condition features for path model\n",
    "        \n",
    "    def __init__(self,npaths_max=25,pl_max=200, nlatent=10,\\\n",
    "                 nunits_enc=(200,80), nunits_dec=(80,200), \\\n",
    "                 nunits_link=(25,10), add_zero_los_frac=0.25,out_var_min=1e-4,\\\n",
    "                 init_bias_stddev=10.0, init_kernel_stddev=10.0,\\\n",
    "                 model_dir='model_data', fc=28e9):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        Parameters\n",
    "        ----------\n",
    "        npaths_max : int\n",
    "            max number of paths per link\n",
    "        pl_max : scalar\n",
    "            max path loss in dB\n",
    "        nunits_enc : list of integers\n",
    "            number of hidden units in each layer of the encoder\n",
    "        nunits_dec : list of integers\n",
    "            number of hidden units in each layer of the decoder\n",
    "        nunits_link:  list of integers\n",
    "            number of hidden units in each layer of the link classifier\n",
    "        nlatent : int\n",
    "            number of latent states in the VAE model\n",
    "        nunits_enc : list of integers\n",
    "            number of hidden units in each layer of the encoder\n",
    "        nunits_dec : list of integers\n",
    "            number of hidden units in each layer of the decoder  \n",
    "        add_zero_los_frac: scalar\n",
    "            in the link state modeling, a fraction of points at the origin\n",
    "            are added to ensure the model predicts a LOS link there.\n",
    "        out_var_min:  scalar\n",
    "            minimum output variance.  This is used for improved conditioning \n",
    "        init_kernel_stddev : scalar\n",
    "            std deviation of the kernel in the initialization\n",
    "        init_bias_stddev : scalar\n",
    "            std deviation of the bias in the initialization\n",
    "        model_dir : string\n",
    "            path to the directory for all the model files.\n",
    "            if this path does not exist, it will be created \n",
    "        fc : scalar\n",
    "            carrier frequency in Hz            \n",
    "        \"\"\"\n",
    "        self.npaths_max = npaths_max\n",
    "        self.pl_max = pl_max\n",
    "        self.ndim = 3  # number of spatial dimensions\n",
    "        self.nunits_link = nunits_link\n",
    "        self.init_kernel_stddev = init_kernel_stddev\n",
    "        self.init_bias_stddev = init_bias_stddev\n",
    "        self.model_dir = model_dir\n",
    "        \n",
    "        self.nlatent = nlatent\n",
    "        self.nunits_enc = nunits_enc\n",
    "        self.nunits_dec = nunits_dec\n",
    "        self.add_zero_los_frac = add_zero_los_frac\n",
    "        self.out_var_min = out_var_min        \n",
    "        self.fc = fc\n",
    "        \n",
    "        \n",
    "    \n",
    "    def transform_link(self,dvec,cell_type,fit=False):\n",
    "        \"\"\"\n",
    "        Pre-processes input for the link classifier network\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,3) array\n",
    "            vector from cell to UAV\n",
    "        cell_type : (nlink,) array of ints\n",
    "            cell type.  One of terr_cell, aerial_cell\n",
    "        Returns\n",
    "        -------\n",
    "        X:  (nlink,nin_link) array:\n",
    "            transformed data for input to the NN\n",
    "        \"\"\"\n",
    "        \n",
    "        # 3D distance and vertical distance.\n",
    "        # Note that vertical distance can be negative\n",
    "        #dx = np.sqrt(np.sum(dvec[:,0]**2, axis=1))\n",
    "        dx = np.sqrt(dvec[:,0]**2 + dvec[:,1]**2)\n",
    "        dz = dvec[:,2]\n",
    "        \n",
    "        X0 = np.column_stack((dx, dz, dx*cell_type, dz*cell_type, cell_type))\n",
    "                    \n",
    "        \n",
    "        # Transform the data with the scaler.\n",
    "        # If fit is set, the transform is also learned\n",
    "        if fit:\n",
    "            self.link_scaler = sklearn.preprocessing.StandardScaler()\n",
    "            X = self.link_scaler.fit_transform(X0)\n",
    "        else:\n",
    "            X = self.link_scaler.transform(X0)\n",
    "        return X\n",
    "        \n",
    "        \n",
    "    def build_link_mod(self):\n",
    "        \"\"\"\n",
    "        Builds the link classifier neural network            \n",
    "        \"\"\"              \n",
    "        \n",
    "        # Input layer\n",
    "        self.link_mod = tfkm.Sequential()\n",
    "        self.link_mod.add(tfkl.Input(self.nin_link, name='Input'))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i, nh in enumerate(self.nunits_link):\n",
    "            self.link_mod.add(tfkl.Dense(nh, activation='sigmoid', name='FC%d' % i))\n",
    "        \n",
    "        # Output softmax for classification\n",
    "        self.link_mod.add(tfkl.Dense(self.nlink_states, activation='softmax', name='Output'))\n",
    "              \n",
    "    \n",
    "    def add_los_zero(self,dvec,cell_type,ls):\n",
    "        \"\"\"\n",
    "        Appends points at dvec=0 with LOS.  This is used to \n",
    "        ensure the model predicts a LOS link at zero distance.\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            vector from cell to UAV\n",
    "        cell_type : (nlink,) array of ints\n",
    "            cell type. \n",
    "        ls : (nlink,) array of ints\n",
    "            link types\n",
    "        Returns\n",
    "        -------\n",
    "        dvec, cell_type, ls : as above\n",
    "            Values with the zeros appended at the end\n",
    "        \"\"\"\n",
    "        \n",
    "        ns = dvec.shape[0]\n",
    "        nadd = int(ns*self.add_zero_los_frac)\n",
    "        if nadd <= 0:\n",
    "            return dvec, cell_type, ls\n",
    "        \n",
    "        I = np.random.randint(ns,size=(nadd,))\n",
    "        \n",
    "        # Variables to append\n",
    "        cell_type1 = cell_type[I]\n",
    "        ls1 = np.tile(ChanMod.los_link, nadd)\n",
    "        dvec1 = np.zeros((nadd,3))\n",
    "        \n",
    "        # Add the points\n",
    "        cell_type = np.hstack((cell_type, cell_type1))\n",
    "        ls = np.hstack((ls, ls1))\n",
    "        dvec = np.vstack((dvec, dvec1))\n",
    "        return dvec, cell_type, ls\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit_link_mod(self, train_data, test_data, epochs=50, lr=1e-4):\n",
    "        \"\"\"\n",
    "        Trains the link classifier model\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_data : dictionary\n",
    "            training data dictionary.\n",
    "        test_data : dictionary\n",
    "            test data dictionary.    \n",
    "        \"\"\"      \n",
    "        \n",
    "        \n",
    "        # Get the link state\n",
    "        ytr = get_link_state(train_data['los_exists'], train_data['nlos_pl'],\\\n",
    "                             self.pl_max)\n",
    "        yts = get_link_state(test_data['los_exists'], test_data['nlos_pl'],\\\n",
    "                             self.pl_max)\n",
    "        \n",
    "        \n",
    "        # Get the position and cell types\n",
    "        dvectr = train_data['dvec']\n",
    "        celltr = train_data['cell_type']\n",
    "        dvects = test_data['dvec']\n",
    "        cellts = test_data['cell_type']\n",
    "        \n",
    "        # Fit the transforms\n",
    "        self.transform_link(dvectr,celltr, fit=True)\n",
    "\n",
    "        # Append the zero points        \n",
    "        dvectr, celltr, ytr = self.add_los_zero(dvectr,celltr,ytr)\n",
    "        dvects, cellts, yts = self.add_los_zero(dvects,cellts,yts)\n",
    "                        \n",
    "        # Transform the input to the neural network\n",
    "        Xtr = self.transform_link(dvectr,celltr)\n",
    "        Xts = self.transform_link(dvects,cellts)\n",
    "                    \n",
    "        # Fit the neural network\n",
    "        opt = Adam(lr=lr)\n",
    "        self.link_mod.compile(opt,loss='sparse_categorical_crossentropy',\\\n",
    "                metrics=['accuracy'])\n",
    "        \n",
    "        self.link_hist = self.link_mod.fit(\\\n",
    "                Xtr,ytr, batch_size=100, epochs=epochs, validation_data=(Xts,yts) )            \n",
    "            \n",
    "    \n",
    "    def link_predict(self,dvec,cell_type):\n",
    "        \"\"\"\n",
    "        Predicts the link state\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            vector from cell to UAV\n",
    "        cell_type : (nlink,) array of ints\n",
    "            cell type.  0 = terrestrial, 1=aerial\n",
    "        Returns\n",
    "        -------\n",
    "        prob:  (nlink,nlink_states) array:\n",
    "            probabilities of each link state\n",
    "        \"\"\"\n",
    "        X = self.transform_link(dvec, cell_type)\n",
    "        prob = self.link_mod.predict(X)\n",
    "        return prob\n",
    "    \n",
    "    def save_link_model(self, weights_fn='link_weights.h5', preproc_fn='link_preproc.p'):\n",
    "        \"\"\"\n",
    "        Saves link state predictor model data to files\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights_fn : string\n",
    "            Filename for the link neural network weights.  This is an H5 file\n",
    "        preproc_fn : string\n",
    "            Filename for the pickle copy of the pre-processors\n",
    "        \"\"\"\n",
    "        # Create the file paths\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        preproc_path = os.path.join(self.model_dir, preproc_fn)\n",
    "        weigths_path = os.path.join(self.model_dir, weights_fn)\n",
    "        \n",
    "        \n",
    "        # Save the pre-processors\n",
    "        with open(preproc_path,'wb') as fp:\n",
    "            pickle.dump([self.link_scaler, self.nunits_link], fp)\n",
    "            \n",
    "        # Save the VAE weights\n",
    "        self.link_mod.save_weights(weigths_path, save_format='h5')\n",
    "        \n",
    "    def load_link_model(self, weights_fn='link_weights.h5', preproc_fn='link_preproc.p'):\n",
    "        \"\"\"\n",
    "        Load link state predictor model data from files\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights_fn : string\n",
    "            Filename for the VAE weights.  This is an H5 file\n",
    "        preproc_fn : string\n",
    "            Filename for the pickle copy of the pre-processors\n",
    "        \"\"\"\n",
    "        # Create the file paths\n",
    "        preproc_path = os.path.join(self.model_dir, preproc_fn)\n",
    "        weigths_path = os.path.join(self.model_dir, weights_fn)\n",
    "\n",
    "        # Load the pre-processors and model config\n",
    "        with open(preproc_path,'rb') as fp:\n",
    "            self.link_scaler, self.nunits_link = pickle.load(fp)\n",
    "            \n",
    "        # Build the link state predictor\n",
    "        self.build_link_mod()\n",
    "        \n",
    "        # Load the VAE weights\n",
    "        self.link_mod.load_weights(weigths_path)\n",
    "        \n",
    "    def build_path_mod(self):\n",
    "        \"\"\"\n",
    "        Builds the VAE for the NLOS paths\n",
    "        \"\"\"\n",
    "        \n",
    "        # Number of data inputs in the transformed domain\n",
    "        # For each sample and each path, there is:\n",
    "        # * one path loss value\n",
    "        # * nangle angles\n",
    "        # * one delay\n",
    "        # for a total of (2+nangle)*npaths_max parameters\n",
    "        self.ndat = self.npaths_max*(2+DataFormat.nangle)\n",
    "        \n",
    "        self.path_mod = CondVAE(\\\n",
    "            nlatent=self.nlatent, ndat=self.ndat, ncond=ChanMod.ncond,\\\n",
    "            nunits_enc=self.nunits_enc, nunits_dec=self.nunits_dec,\\\n",
    "            out_var_min=self.out_var_min, nsort=self.npaths_max,\\\n",
    "            init_bias_stddev=self.init_bias_stddev,\\\n",
    "            init_kernel_stddev=self.init_kernel_stddev)\n",
    "            \n",
    "    def fit_path_mod(self, train_data, test_data, epochs=50, lr=1e-3,\\\n",
    "                     checkpoint_period = 0):\n",
    "        \"\"\"\n",
    "        Trains the path model\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_data : dictionary\n",
    "            training data dictionary.\n",
    "        test_data : dictionary\n",
    "            test data dictionary. \n",
    "        epochs: int\n",
    "            number of training epochs\n",
    "        lr: scalar\n",
    "            learning rate\n",
    "        checkpoint_period:  int\n",
    "            period in epochs for saving the model checkpoints.  \n",
    "            A value of 0 indicates that checkpoints are not be saved.\n",
    "        \"\"\"      \n",
    "        # Get the link state\n",
    "        ls_tr = get_link_state(train_data['los_exists'], train_data['nlos_pl'],\\\n",
    "                               self.pl_max)\n",
    "        ls_ts = get_link_state(test_data['los_exists'], test_data['nlos_pl'],\\\n",
    "                               self.pl_max)\n",
    "        los_tr = ls_tr == ChanMod.los_link\n",
    "        los_ts = ls_tr == ChanMod.los_link\n",
    "        \n",
    "        \n",
    "        # Extract the links that are in LOS or NLOS\n",
    "        Itr = np.where(ls_tr != ChanMod.no_link)[0]\n",
    "        Its = np.where(ls_ts != ChanMod.no_link)[0]\n",
    "        \n",
    "        # Fit and transform the condition data\n",
    "        Utr = self.transform_cond(\\\n",
    "            train_data['dvec'][Itr], train_data['cell_type'][Itr],\\\n",
    "            los_tr[Itr], fit=True)\n",
    "        Uts = self.transform_cond(\\\n",
    "            test_data['dvec'][Its], test_data['cell_type'][Its],\\\n",
    "            los_ts[Its])            \n",
    "        \n",
    "        # Fit and transform the data\n",
    "        Xtr = self.transform_data(\\\n",
    "            train_data['dvec'][Itr],\\\n",
    "            train_data['nlos_pl'][Itr,:self.npaths_max],\\\n",
    "            train_data['nlos_ang'][Itr,:self.npaths_max,:],\\\n",
    "            train_data['nlos_dly'][Itr,:self.npaths_max], fit=True)\n",
    "        Xts  = self.transform_data(\\\n",
    "            test_data['dvec'][Its],\\\n",
    "            test_data['nlos_pl'][Its,:self.npaths_max],\\\n",
    "            test_data['nlos_ang'][Its,:self.npaths_max,:],\\\n",
    "            test_data['nlos_dly'][Its,:self.npaths_max])\n",
    "        \n",
    "        # Create the checkpoint callback\n",
    "        batch_size = 100\n",
    "        if (checkpoint_period > 0):            \n",
    "            save_freq = checkpoint_period*int(np.ceil(Xtr.shape[0]/batch_size))\n",
    "            if not os.path.exists(self.model_dir):\n",
    "                os.makedirs(self.model_dir)\n",
    "            cp_path = os.path.join(self.model_dir, 'path_weights.{epoch:03d}.h5')\n",
    "            callbacks = [tf.keras.callbacks.ModelCheckpoint(\\\n",
    "                filepath=cp_path, save_weights_only=True,save_freq=save_freq)]\n",
    "        else:\n",
    "            callbacks = []\n",
    "        \n",
    "        \n",
    "        # Fit the model\n",
    "        opt = Adam(lr=lr)\n",
    "        self.path_mod.vae.compile(opt)\n",
    "            \n",
    "        self.path_hist = self.path_mod.vae.fit(\\\n",
    "                    [Xtr,Utr], batch_size=batch_size, epochs=epochs,\\\n",
    "                    validation_data=([Xts,Uts],None),\\\n",
    "                    callbacks=callbacks)\n",
    "        \n",
    "        # Save the history\n",
    "        hist_path = os.path.join(self.model_dir, 'path_train_hist.p')        \n",
    "        with open(hist_path,'wb') as fp:\n",
    "            pickle.dump(self.path_hist.history, fp)\n",
    "            \n",
    "    def transform_dly(self, dvec, nlos_dly, fit=False):\n",
    "        \"\"\"\n",
    "        Performs the transformation on the delay data\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array, ndim=3\n",
    "            Vectors from cell to UAV for each link\n",
    "        nlos_dly : (nlink,npaths_max) array \n",
    "            Absolute delay of each path in each link  \n",
    "        fit:  boolean\n",
    "            Indicates if transform is to be fit\n",
    "        Returns\n",
    "        -------\n",
    "        Xdly : (nlink,npaths_max)\n",
    "            Tranformed delay coordinates\n",
    "        \"\"\"            \n",
    "        \n",
    "        # Compute LOS delay\n",
    "        dist = np.sqrt(np.sum(dvec**2,axis=1))        \n",
    "        los_dly = dist/PhyConst.light_speed\n",
    "        \n",
    "        # Compute delay relative to LOS delay\n",
    "        dly0 = np.maximum(0, nlos_dly - los_dly[:,None])\n",
    "                \n",
    "        # Transform the data with the scaler\n",
    "        # If fit is set, the transform is also learned\n",
    "        if fit:            \n",
    "            self.dly_scale = np.mean(dly0)\n",
    "        Xdly = dly0 / self.dly_scale\n",
    "            \n",
    "        return Xdly\n",
    "    \n",
    "    def inv_transform_dly(self, dvec, Xdly):\n",
    "        \"\"\"\n",
    "        Performs the inverse transformation on the delay data\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array, ndim=3\n",
    "            Vectors from cell to UAV for each link\n",
    "        Xdly : (nlink,npaths_max)\n",
    "            Tranformed delay coordinates\n",
    "        Returns\n",
    "        -------            \n",
    "        nlos_dly : (nlink,npaths_max) array \n",
    "            Absolute delay of each path in each link  \n",
    "        \"\"\"            \n",
    "        \n",
    "        # Compute LOS delay\n",
    "        dist = np.sqrt(np.sum(dvec**2,axis=1))        \n",
    "        los_dly = dist/PhyConst.light_speed\n",
    "        \n",
    "\n",
    "        # Inverse the transform\n",
    "        dly0 = Xdly * self.dly_scale\n",
    "        \n",
    "        # Compute the absolute delay\n",
    "        nlos_dly = dly0 + los_dly[:,None]\n",
    "               \n",
    "        return nlos_dly\n",
    "    \n",
    "            \n",
    "            \n",
    "    def transform_ang(self, dvec, nlos_ang, nlos_pl):\n",
    "        \"\"\"\n",
    "        Performs the transformation on the angle data\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            Vectors from cell to UAV for each link\n",
    "        nlos_ang : (nlink,npaths_max,nangle) array\n",
    "            Angles of each path in each link.  \n",
    "            The angles are in degrees\n",
    "        nlos_pl : (nlink,npaths_max) array \n",
    "            Path losses of each path in each link.\n",
    "            A value of pl_max indicates no path\n",
    "        Returns\n",
    "        -------\n",
    "        Xang : (nlink,nangle*npaths_max)\n",
    "            Tranformed angle coordinates\n",
    "        \"\"\"\n",
    "                \n",
    "        # Compute the LOS angles\n",
    "        r, los_aod_phi, los_aod_theta = cart_to_sph(dvec)\n",
    "        r, los_aoa_phi, los_aoa_theta = cart_to_sph(-dvec)\n",
    "        \n",
    "        # Get the NLOS angles\n",
    "        nlos_aod_phi   = nlos_ang[:,:,DataFormat.aod_phi_ind]\n",
    "        nlos_aod_theta = nlos_ang[:,:,DataFormat.aod_theta_ind]\n",
    "        nlos_aoa_phi   = nlos_ang[:,:,DataFormat.aoa_phi_ind]\n",
    "        nlos_aoa_theta = nlos_ang[:,:,DataFormat.aoa_theta_ind]\n",
    "        \n",
    "        # Rotate the NLOS angles by the LOS angles to compute\n",
    "        # the relative angle        \n",
    "        aod_phi_rel, aod_theta_rel = spherical_add_sub(\\\n",
    "            nlos_aod_phi, nlos_aod_theta,\\\n",
    "            los_aod_phi[:,None], los_aod_theta[:,None])\n",
    "        aoa_phi_rel, aoa_theta_rel = spherical_add_sub(\\\n",
    "            nlos_aoa_phi, nlos_aoa_theta,\\\n",
    "            los_aoa_phi[:,None], los_aoa_theta[:,None])            \n",
    "            \n",
    "        # Set the relative angle on non-existent paths to zero\n",
    "        I = (nlos_pl < self.pl_max-0.01)\n",
    "        aod_phi_rel = aod_phi_rel*I\n",
    "        aod_theta_rel = aod_theta_rel*I\n",
    "        aoa_phi_rel = aoa_phi_rel*I\n",
    "        aoa_theta_rel = aoa_theta_rel*I\n",
    "                                        \n",
    "        # Stack the relative angles and scale by 180\n",
    "        Xang = np.hstack(\\\n",
    "            (aoa_phi_rel/180, aoa_theta_rel/180,\\\n",
    "             aod_phi_rel/180, aod_theta_rel/180))\n",
    "        \n",
    "        return Xang\n",
    "    \n",
    "    def inv_transform_ang(self, dvec, Xang):\n",
    "        \"\"\"\n",
    "        Performs the transformation on the angle data\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            Vectors from cell to UAV for each link\n",
    "        Xang : (nlink,nangle*npaths_max)\n",
    "            Tranformed angle coordinates            \n",
    "   \n",
    "        Returns\n",
    "        -------\n",
    "        nlos_ang : (nlink,npaths_max,nangle) array\n",
    "            Angles of each path in each link.  \n",
    "            The angles are in degrees        \n",
    "        \"\"\"\n",
    "                \n",
    "        # Compute the LOS angles\n",
    "        r, los_aod_phi, los_aod_theta = cart_to_sph(dvec)\n",
    "        r, los_aoa_phi, los_aoa_theta = cart_to_sph(-dvec)\n",
    "        \n",
    "        # Get the transformed angles\n",
    "        npm = self.npaths_max\n",
    "        aoa_phi_rel   = Xang[:,:npm]*180\n",
    "        aoa_theta_rel = Xang[:,npm:2*npm]*180        \n",
    "        aod_phi_rel   = Xang[:,2*npm:3*npm]*180\n",
    "        aod_theta_rel = Xang[:,3*npm:]*180        \n",
    "                \n",
    "        # Rotate the relative angles by the LOS angles to compute\n",
    "        # the original NLOS angles\n",
    "        nlos_aoa_phi, nlos_aoa_theta = spherical_add_sub(\\\n",
    "            aoa_phi_rel, aoa_theta_rel,\\\n",
    "            los_aoa_phi[:,None], los_aoa_theta[:,None], sub=False)\n",
    "        nlos_aod_phi, nlos_aod_theta = spherical_add_sub(\\\n",
    "            aod_phi_rel, aod_theta_rel,\\\n",
    "            los_aod_phi[:,None], los_aod_theta[:,None], sub=False)\n",
    "            \n",
    "        # Stack the relative angles     \n",
    "        nlink = nlos_aod_phi.shape[0]\n",
    "        nlos_ang = np.zeros((nlink,self.npaths_max,DataFormat.nangle))\n",
    "        nlos_ang[:,:,DataFormat.aoa_phi_ind] = nlos_aoa_phi\n",
    "        nlos_ang[:,:,DataFormat.aoa_theta_ind] = nlos_aoa_theta\n",
    "        nlos_ang[:,:,DataFormat.aod_phi_ind] = nlos_aod_phi\n",
    "        nlos_ang[:,:,DataFormat.aod_theta_ind] = nlos_aod_theta\n",
    "        \n",
    "        return nlos_ang\n",
    "                    \n",
    "        \n",
    "    def transform_cond(self, dvec, cell_type, los, fit=False):\n",
    "        \"\"\"\n",
    "        Pre-processing transform on the condition\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            vector from cell to UAV\n",
    "        cell_type : (nlink,) array of ints\n",
    "            cell type.  One of terr_cell, aerial_cell\n",
    "        los:  (nlink,) array of booleans\n",
    "            indicates if link is in LOS or not\n",
    "        fit : boolean\n",
    "            flag indicating if the transform should be fit\n",
    "        Returns\n",
    "        -------\n",
    "        U : (nlink,ncond) array\n",
    "            Transform conditioned features\n",
    "        \"\"\"\n",
    "      \n",
    "        \n",
    "        # 3D distance and vertical distance.\n",
    "        # Note that vertical distance can be negative\n",
    "        d3d = np.maximum(np.sqrt(np.sum(dvec**2, axis=1)), 1)\n",
    "        dvert = dvec[:,2]\n",
    "        \n",
    "        # Transform the condition variables\n",
    "        U0 = np.column_stack((d3d, np.log10(d3d), dvert, cell_type, los))\n",
    "        self.ncond = U0.shape[1]\n",
    "        \n",
    "        # Transform the data with the scaler.\n",
    "        # If fit is set, the transform is also learned\n",
    "        if fit:\n",
    "            self.cond_scaler = sklearn.preprocessing.StandardScaler()\n",
    "            U = self.cond_scaler.fit_transform(U0)\n",
    "        else:\n",
    "            U = self.cond_scaler.transform(U0)\n",
    "            \n",
    "        return U\n",
    "      \n",
    "    def transform_pl(self, nlos_pl, fit=False):\n",
    "        \"\"\"\n",
    "        Transform on the NLOS path loss\n",
    "        Parameters\n",
    "        ----------\n",
    "        pl : (nlink,npaths_max) array \n",
    "            path losses of each NLOS path in each link.\n",
    "            A value of pl_max indicates no path\n",
    "        fit : boolean\n",
    "            flag indicating if the transform should be fit            \n",
    "        Returns\n",
    "        -------\n",
    "        Xpl : (nlink,npaths_max) array\n",
    "            Transform data features\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute the path loss below the maximum path loss.\n",
    "        # Hence a value of 0 corresponds to a maximum path loss value\n",
    "        X0 = self.pl_max - nlos_pl[:,:self.npaths_max]     \n",
    "        \n",
    "        # Transform the data with the scaler.\n",
    "        # If fit is set, the transform is also learned\n",
    "        if fit:\n",
    "            self.pl_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "            Xpl = self.pl_scaler.fit_transform(X0)\n",
    "        else:\n",
    "            Xpl = self.pl_scaler.transform(X0)\n",
    "        return Xpl\n",
    "    \n",
    "    def inv_transform_pl(self, Xpl):\n",
    "        \"\"\"\n",
    "        Inverts the transform on the NLOS path loss data\n",
    "        Parameters\n",
    "        ----------\n",
    "        Xpl : (nlink,ndat) array \n",
    "            Transformed path loss values\n",
    "        Returns\n",
    "        -------\n",
    "        nlos_pl : (nlink,npaths_max) array \n",
    "            Path losses of each NLOS path in each link.\n",
    "            A value of pl_max indicates no path\n",
    "        \"\"\"\n",
    "        \n",
    "        # Invert the scaler\n",
    "        Xpl = np.maximum(0,Xpl)\n",
    "        Xpl = np.minimum(1,Xpl)\n",
    "        X0 = self.pl_scaler.inverse_transform(Xpl)\n",
    "        \n",
    "        # Sort and make positive\n",
    "        X0 = np.maximum(0, X0)\n",
    "        X0 = np.fliplr(np.sort(X0, axis=-1))\n",
    "        \n",
    "        # Transform the condition variables\n",
    "        nlos_pl = self.pl_max - X0  \n",
    "                \n",
    "        return nlos_pl        \n",
    "        \n",
    "    def transform_data(self, dvec, nlos_pl, nlos_ang, nlos_dly, fit=False):\n",
    "        \"\"\"\n",
    "        Pre-processing transform on the data\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            vector from cell to UAV\n",
    "        nlos_pl : (nlink,npaths_max) array \n",
    "            Path losses of each path in each link.\n",
    "            A value of pl_max indicates no path\n",
    "        nlos_ang : (nlink,npaths_max,nangle) array\n",
    "            Angles of each path in each link.  \n",
    "            The angles are in degrees           \n",
    "        nlos_dly : (nlink,npaths_max) array \n",
    "            Absolute delay of each path (in seconds)\n",
    "        fit : boolean\n",
    "            flag indicating if the transform should be fit            \n",
    "        Returns\n",
    "        -------\n",
    "        X : (nlink,ndat) array\n",
    "            Transform data features\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform the path loss data\n",
    "        Xpl = self.transform_pl(nlos_pl,fit)\n",
    "        \n",
    "        # Transform the angles\n",
    "        Xang = self.transform_ang(dvec,nlos_ang,nlos_pl)\n",
    "        \n",
    "        # Transform the delays\n",
    "        Xdly = self.transform_dly(dvec, nlos_dly, fit)\n",
    "        \n",
    "        # Concatenate\n",
    "        X = np.hstack((Xpl, Xang, Xdly))\n",
    "        return X\n",
    "    \n",
    "    def inv_transform_data(self, dvec, X):\n",
    "        \"\"\"\n",
    "        Inverts the pre-processing transform on the data\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            vector from cell to UAV\n",
    "        X : (nlink,ndat) array \n",
    "            Transform data features\n",
    "        Returns\n",
    "        -------\n",
    "        nlos_pl : (nlink,npaths_max) array \n",
    "            Path losses of each path in each link.\n",
    "            A value of pl_max indicates no path\n",
    "        nlos_ang : (nlink,npaths_max,nangle) array\n",
    "            Angles of each path in each link.  \n",
    "            The angles are in degrees\n",
    "        nlos_dly : (nlink,npaths_max) array \n",
    "            Absolute delay of each path (in seconds)            \n",
    "        \"\"\"\n",
    "        \n",
    "        # Split\n",
    "        Xpl = X[:,:self.npaths_max]\n",
    "        Xang = X[:,self.npaths_max:self.npaths_max*(DataFormat.nangle+1)]\n",
    "        Xdly = X[:,self.npaths_max*(DataFormat.nangle+1):]\n",
    "        \n",
    "        # Invert the transforms\n",
    "        nlos_pl = self.inv_transform_pl(Xpl)\n",
    "        nlos_ang = self.inv_transform_ang(dvec, Xang)\n",
    "        nlos_dly = self.inv_transform_dly(dvec, Xdly)\n",
    "        \n",
    "                \n",
    "        return nlos_pl, nlos_ang, nlos_dly\n",
    "    \n",
    "    def get_los_path(self, dvec):\n",
    "        \"\"\"\n",
    "        Computes LOS path loss and angles\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (n,3) array            \n",
    "            Vector from cell to UAV\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        los_pl:  (n,) array\n",
    "            LOS path losses computed from Friis' Law\n",
    "        los_ang:  (n,DataFormat.nangle) = (n,4) array\n",
    "            LOS angles \n",
    "        los_dly:  (n,) array\n",
    "            Delay of the paths computed from the speed of light\n",
    "        \"\"\"\n",
    "        # Compute free space path loss from Friis' law\n",
    "        dist = np.maximum(np.sqrt(np.sum(dvec**2,axis=1)), 1)        \n",
    "        lam = 3e8/self.fc\n",
    "        los_pl = 20*np.log10(dist*4*np.pi/lam)\n",
    "        \n",
    "        # Compute the LOS angles\n",
    "        r, los_aod_phi, los_aod_theta = cart_to_sph(dvec)\n",
    "        r, los_aoa_phi, los_aoa_theta = cart_to_sph(-dvec)\n",
    "        \n",
    "        # Stack the angles\n",
    "        los_ang = np.stack((los_aoa_phi, los_aoa_theta,\\\n",
    "                            los_aod_phi, los_aod_theta), axis=-1)\n",
    "            \n",
    "        # Compute the delay\n",
    "        los_dly = dist/PhyConst.light_speed\n",
    "    \n",
    "        return los_pl, los_ang, los_dly\n",
    "        \n",
    "    \n",
    "    def sample_path(self, dvec, cell_type, link_state=None, nlos_only=False):\n",
    "        \"\"\"\n",
    "        Generates random samples of the path data using the trained model\n",
    "        Parameters\n",
    "        ----------\n",
    "        dvec : (nlink,ndim) array\n",
    "            Vector from cell to UAV\n",
    "        cell_type : (nlink,) array of ints\n",
    "            Cell type.  One of terr_cell, aerial_cell\n",
    "        link_state:  (nlink,) array of {no_link, los_link, nlos_link}            \n",
    "            A value of `None` indicates that the link state should be\n",
    "            generated randomly from the link state predictor model\n",
    "        nlos_only: Boolean\n",
    "            If `True`, returns only the NLOS path data.\n",
    "            If `False`, returns the LOS and NLOS path data.\n",
    "   \n",
    "        Returns\n",
    "        -------\n",
    "        pl : (nlink,npaths_max) array \n",
    "            Path losses of each path in each link.\n",
    "            A value of pl_max indicates no path\n",
    "        ang: (nlink,npaths_max,DataFormat.nangle) array\n",
    "            Angles of each pathin each link\n",
    "        dly : (nlink,npaths_max) array \n",
    "            Absolute delay of each path in each link in seconds.           \n",
    "        \"\"\"\n",
    "        # Get dimensions\n",
    "        nlink = dvec.shape[0]\n",
    "\n",
    "        # Generate random link states if needed\n",
    "        # Use the link state predictor network\n",
    "        if link_state is None:\n",
    "            prob = self.link_predict(dvec, cell_type) \n",
    "            cdf = np.cumsum(prob, axis=1)            \n",
    "            link_state = np.zeros(nlink)\n",
    "            u = np.random.uniform(0,1,nlink)\n",
    "            for i in range(cdf.shape[1]-1):\n",
    "                I = np.where(u>cdf[:,i])[0]\n",
    "                link_state[I] = i+1\n",
    "                \n",
    "        # Find the indices where there are some link\n",
    "        # and where there is a LOS link\n",
    "        Ilink = np.where(link_state != ChanMod.no_link)[0]\n",
    "        Ilos  = np.where(link_state == ChanMod.los_link)[0]\n",
    "        los   = link_state == ChanMod.los_link        \n",
    "        \n",
    "        # Get the condition variables and random noise\n",
    "        U = self.transform_cond(dvec[Ilink], cell_type[Ilink], los[Ilink])\n",
    "        nlink1 = U.shape[0]\n",
    "        Z = np.random.normal(0,1,(nlink1,self.nlatent))\n",
    "        \n",
    "        # Run through the sampling network\n",
    "        X = self.path_mod.sampler.predict([Z,U]) \n",
    "        \n",
    "        # Compute the inverse transform to get back the path loss\n",
    "        # and angle data\n",
    "        nlos_pl, nlos_ang , nlos_dly = self.inv_transform_data(dvec[Ilink], X)\n",
    "        \n",
    "        # Create arrays for the PL and angles\n",
    "        pl  = np.tile(self.pl_max, (nlink,self.npaths_max))\n",
    "        ang = np.zeros((nlink,self.npaths_max,DataFormat.nangle))\n",
    "        dly  = np.tile(self.pl_max, (nlink,self.npaths_max))\n",
    "        \n",
    "        # Place the NLOS data in the arrays \n",
    "        pl[Ilink]  = nlos_pl\n",
    "        ang[Ilink] = nlos_ang\n",
    "        dly[Ilink]  = nlos_dly\n",
    "        \n",
    "        if not nlos_only:\n",
    "        \n",
    "            # Compute the PL and angles for the LOS paths\n",
    "            los_pl, los_ang, los_dly = self.get_los_path(dvec[Ilos])\n",
    "            \n",
    "            # Add the path loss and angles to the NLOS paths\n",
    "            # On the links with LOS paths, move over the\n",
    "            # the NLOS data and insert the NLOS paths\n",
    "            pl[Ilos,1:] = pl[Ilos,:-1]\n",
    "            ang[Ilos,1:,:] = ang[Ilos,:-1,:]\n",
    "            dly[Ilos,1:] = dly[Ilos,:-1]\n",
    "            pl[Ilos,0] = los_pl\n",
    "            ang[Ilos,0,:] = los_ang\n",
    "            dly[Ilos,0] = los_dly\n",
    "            \n",
    "        return pl, ang, dly\n",
    "            \n",
    "    \n",
    "    def save_path_model(self, weights_fn='path_weights.h5', preproc_fn='path_preproc.p'):\n",
    "        \"\"\"\n",
    "        Saves model data to files\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights_fn : string\n",
    "            Filename for the VAE weights.  This is an H5 file\n",
    "        preproc_fn : string\n",
    "            Filename for the pickle copy of the pre-processors\n",
    "        \"\"\"\n",
    "        # Create the file paths\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        preproc_path = os.path.join(self.model_dir, preproc_fn)\n",
    "        weigths_path = os.path.join(self.model_dir, weights_fn)\n",
    "        \n",
    "        # Save the pre-processors\n",
    "        with open(preproc_path,'wb') as fp:\n",
    "            pickle.dump([self.pl_scaler, self.cond_scaler, self.dly_scale,\\\n",
    "                         self.pl_max, self.npaths_max, self.nlatent,\\\n",
    "                         self.nunits_enc, self.nunits_dec], fp)\n",
    "            \n",
    "        # Save the VAE weights\n",
    "        self.path_mod.vae.save_weights(weigths_path, save_format='h5')\n",
    "        \n",
    "    def load_path_model(self, weights_fn='path_weights.h5', preproc_fn='path_preproc.p'):\n",
    "        \"\"\"\n",
    "        Load model data from files\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights_fn : string\n",
    "            Filename for the VAE weights.  This is an H5 file\n",
    "        preproc_fn : string\n",
    "            Filename for the pickle copy of the pre-processors\n",
    "        \"\"\"\n",
    "        # Create the file paths\n",
    "        preproc_path = os.path.join(self.model_dir, preproc_fn)\n",
    "        weights_path = os.path.join(self.model_dir, weights_fn)\n",
    "        \n",
    "        # Load the pre-processors\n",
    "        with open(preproc_path,'rb') as fp:\n",
    "            self.pl_scaler, self.cond_scaler, self.dly_scale, self.pl_max,\\\n",
    "                self.npaths_max, self.nlatent, self.nunits_enc,\\\n",
    "                self.nunits_dec = pickle.load(fp)\n",
    "            \n",
    "        # Build the path model\n",
    "        self.build_path_mod()\n",
    "            \n",
    "        # Load the VAE weights\n",
    "        self.path_mod.vae.load_weights(weights_path)\n",
    "        \n",
    "def set_initialization(mod, layer_names, kernel_stddev=1.0, bias_stddev=1.0):\n",
    "    \"\"\"\n",
    "    Sets the bias and kernel initializations for a set of dense layers\n",
    "    Parameters\n",
    "    ----------\n",
    "    mod:  Tensorflow model\n",
    "        Model for which the initialization is to be applied\n",
    "    layer_names : list of strings\n",
    "        List of names of layers to apply the initialization\n",
    "    kernel_stddev : scalar\n",
    "        std deviation of the kernel in the initialization\n",
    "    bias_stddev : scalar\n",
    "        std deviation of the bias in the initialization            \n",
    "    \"\"\"\n",
    "    for name in layer_names:\n",
    "        layer = mod.get_layer(name)\n",
    "        nin = layer.input_shape[-1]\n",
    "        nout = layer.output_shape[-1]\n",
    "        W = np.random.normal(0,kernel_stddev/np.sqrt(nin),\\\n",
    "                             (nin,nout)).astype(np.float32)\n",
    "        b = np.random.normal(0,bias_stddev,\\\n",
    "                             (nout,)).astype(np.float32)\n",
    "        layer.set_weights([W,b])\n",
    "        \n",
    "def combine_los_nlos(nlos_pl, nlos_ang, nlos_dly,\\\n",
    "                     los_exists, los_pl, los_ang, los_dly):\n",
    "    \"\"\"\n",
    "    Combines LOS and NLOS path loss data\n",
    "    Parameters\n",
    "    ----------    \n",
    "    nlos_pl : (nlink,npaths_max) array\n",
    "        NLOS path losses for each path in dB\n",
    "    nlos_ang : (nlink,npaths_max,nangle) array \n",
    "        Set of angles of each path in degrees\n",
    "    nlos_dly : (nlink,npaths_max) array\n",
    "        NLOS absolute delays of each path in seconds\n",
    "    los_exists : (nlink,) array of booleans\n",
    "        For each link, indicates if there is a LOS path.\n",
    "        The LOS paths will be added only on these links\n",
    "    los_pl : (nlink,) array\n",
    "        LOS path losses for each link in dB.  \n",
    "    los_ang : (nlink,npaths_max,) array \n",
    "        Set of LOS angles of each link\n",
    "    los_dly : (nlink,) array\n",
    "        LOS absolute delays of each path in seconds\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pl : (nlink,npaths_max) array\n",
    "        Combined path losses for each path in dB\n",
    "    ang : (nlink,npaths_max,nangle) array \n",
    "        Combined of angles of each path in degrees\n",
    "    dly : (nlink,npaths_max) array\n",
    "        Combined absolute delays of each path in seconds\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    # Find the links with LOS paths\n",
    "    Ilos = np.where(los_exists)[0]\n",
    "    \n",
    "    # Copy the NLOS path losses and angles\n",
    "    pl = np.copy(nlos_pl)\n",
    "    ang = np.copy(nlos_ang)\n",
    "    dly = np.copy(nlos_dly)\n",
    "    \n",
    "    # On the links with LOS paths, move over the\n",
    "    # the NLOS data and insert the NLOS paths\n",
    "    pl[Ilos,1:] = pl[Ilos,:-1]\n",
    "    ang[Ilos,1:,:] = ang[Ilos,:-1,:]\n",
    "    dly[Ilos,1:] = dly[Ilos,:-1]\n",
    "    pl[Ilos,0] = los_pl[Ilos]\n",
    "    ang[Ilos,0,:] = los_ang[Ilos,:]\n",
    "    dly[Ilos,0] = los_dly[Ilos]\n",
    "            \n",
    "    return pl, ang, dly\n",
    "        \n",
    "        \n",
    "        \n",
    "def get_link_state(los_exists, nlos_pl, pl_max):\n",
    "    \"\"\"\n",
    "    Computes the link state\n",
    "    Parameters\n",
    "    ----------\n",
    "    los_exists : (nlink,) array of boolean\n",
    "        indicates if each link has an LOS path or not\n",
    "    nlos_pl : (nlink,npaths_max) array of floats\n",
    "        path loss for each path in the link\n",
    "    pl_max : scalar\n",
    "        Maximum path loss.  Values close to this value\n",
    "        are considered non-existent\n",
    "    Returns\n",
    "    -------\n",
    "    link_state : (nlink,) array of int\n",
    "        indicates link state: no_link, los_link, nlos_link            \n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute number of paths for each link\n",
    "    npath = np.sum((nlos_pl < pl_max-0.1), axis=1)\n",
    "    \n",
    "    # Compute link state\n",
    "    Ilos  = (los_exists==1)\n",
    "    Ino   = (los_exists==0) & (npath==0)\n",
    "    Inlos = (los_exists==0) & (npath>0)\n",
    "    \n",
    "    link_state = ChanMod.los_link*Ilos + ChanMod.nlos_link*Inlos\\\n",
    "        + ChanMod.no_link*Ino\n",
    "    return link_state    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
